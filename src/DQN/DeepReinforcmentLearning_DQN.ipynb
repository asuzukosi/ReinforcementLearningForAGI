{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbcIWrDkgLg1u0xuQE45g+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asuzukosi/ReinforcementLearningForAGI/blob/main/src/DQN/DeepReinforcmentLearning_DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Q-Networks\n",
        "In this notebook, we will explore the implementation of the base vanilla DQN algorithm to the rainbow DQN. We will explore the use of these algorithms across various gym environments. We will use 3 environments for each model."
      ],
      "metadata": {
        "id": "vasvYXHes_vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install required libraries\n",
        "We will install the required libraries for environments and models we need"
      ],
      "metadata": {
        "id": "Rj6HgnwItiop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !apt-get install -y python3-opengl\n",
        "    !apt install ffmpeg\n",
        "    !apt install xvfb\n",
        "    !pip install PyVirtualDisplay==3.0\n",
        "    !pip install gymnasium==0.28.1\n",
        "    from pyvirtualdisplay import Display\n",
        "\n",
        "    # Start virtual display\n",
        "    dis = Display(visible=0, size=(400, 400))\n",
        "    dis.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgjiiNNGuJCZ",
        "outputId": "6c7acfee-6c8d-4248-8089-9f4ced55e5f7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libglu1-mesa\n",
            "Suggested packages:\n",
            "  libgle3 python3-numpy\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 libglu1-mesa python3-opengl\n",
            "0 upgraded, 3 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 824 kB of archives.\n",
            "After this operation, 8,092 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-opengl all 3.1.5+dfsg-1 [605 kB]\n",
            "Fetched 824 kB in 1s (1,236 kB/s)\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 120874 files and directories currently installed.)\n",
            "Preparing to unpack .../freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package python3-opengl.\n",
            "Preparing to unpack .../python3-opengl_3.1.5+dfsg-1_all.deb ...\n",
            "Unpacking python3-opengl (3.1.5+dfsg-1) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up python3-opengl (3.1.5+dfsg-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 7,812 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.1 [28.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.1 [863 kB]\n",
            "Fetched 7,812 kB in 2s (4,486 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 123958 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.1_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.1_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.1) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.1) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Collecting PyVirtualDisplay==3.0\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: PyVirtualDisplay\n",
            "Successfully installed PyVirtualDisplay-3.0\n",
            "Collecting gymnasium==0.28.1\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1) (1.23.5)\n",
            "Collecting jax-jumpy>=1.0.0 (from gymnasium==0.28.1)\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium==0.28.1)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, jax-jumpy, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install pyglet\n",
        "!pip install gymnasium[classic-control]\n",
        "!pip install PyVirtualDisplay\n",
        "!pip install moviepy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dILEQGTtr0A",
        "outputId": "63c00616-db36-4ddf-cb43-1f5143874bb0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pyglet in /usr/local/lib/python3.10/dist-packages (2.0.9)\n",
            "Requirement already satisfied: gymnasium[classic-control] in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (1.23.5)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (0.0.4)\n",
            "Requirement already satisfied: pygame==2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (2.1.3)\n",
            "Requirement already satisfied: PyVirtualDisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.23.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.5)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import required libraries\n",
        "In this section we will import all the required libraries to implement our algorithms"
      ],
      "metadata": {
        "id": "UKJufeCvuPc0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3M2MHbrOs63i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from typing import Dict, List, Tuple\n",
        "import gymnasium as gym\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Replay Buffer\n",
        "Replay buffer is used to store the previous experiences in order to stabilize training of the DQN.\n",
        "The replay buffer is implemented in one of the following\n",
        "- numpy\n",
        "- dequeue\n",
        "- list\n",
        "\n",
        "In our implementation of the replay buffer we will be using numpy arrays as they benefit for locality of reference, so this well speed up the retreival time of items"
      ],
      "metadata": {
        "id": "0A95yvtpin2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "  def __init__(self, obs_dim:int, size:int, batch_size:int=32):\n",
        "    # we create empty lists to store the information in the buffers\n",
        "    self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "    self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "    self.acts_buf = np.zeros([size], dtype=np.float32)\n",
        "    self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "    self.done_buf = np.zeros(size, dtype=np.float32)\n",
        "    # set the batch size and the maximum size of the replay buffer\n",
        "    self.max_size, self.batch_size = size, batch_size\n",
        "    # set the pointer value and the size value\n",
        "    self.ptr, self.size, = 0, 0\n",
        "\n",
        "  def store(self, obs, action, reward, next_obs, done):\n",
        "    self.obs_buf[self.ptr] = obs\n",
        "    self.next_obs_buf[self.ptr] = next_obs\n",
        "    self.acts_buf[self.ptr] = action\n",
        "    self.rews_buf[self.ptr] = reward\n",
        "    self.done_buf[self.ptr] = done\n",
        "    # set the pointer value to the modulus of the max size and the current pointer +1\n",
        "    self.ptr = (self.ptr + 1) % self.max_size\n",
        "    # if the size exceeds the max size, set the value to max size\n",
        "    self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "    idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "    return dict(obs=self.obs_buf[idxs],\n",
        "                acts=self.acts_buf[idxs],\n",
        "                rews=self.rews_buf[idxs],\n",
        "                next_obs=self.next_obs_buf[idxs],\n",
        "                done=self.done_buf[idxs])\n",
        "  def __len__(self):\n",
        "    return self.size"
      ],
      "metadata": {
        "id": "EuePWJoKkX24"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Network implementation\n",
        "In this section we will focus on implementing the neural network for our DQN algorithm"
      ],
      "metadata": {
        "id": "DMfDba5OoLUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self, inp_dim:int, out_dim:int, hidden_dim=128):\n",
        "    # initiation\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(inp_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, out_dim),\n",
        "        # nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # equation\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "_ZyYFziXoKdg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQNAgent:\n",
        "  \"\"\"\n",
        "  This class handles the training and inference of\n",
        "  the DQN agent class\n",
        "  \"\"\"\n",
        "  def __init__(self, env, memory_size:int, batch_size,\n",
        "               target_update, epsilon_decay, seed,\n",
        "               max_epsilon:float=1.0, min_epsilon:float=0.1,\n",
        "               gamma:float=0.99):\n",
        "    obs_dim = env.observation_space.shape[0]\n",
        "    act_dim = env.action_space.n\n",
        "\n",
        "    self.env = env\n",
        "    self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n",
        "    self.batch_size = batch_size\n",
        "    self.epsilon = max_epsilon\n",
        "    self.epsilon_decay = epsilon_decay\n",
        "    self.seed = seed\n",
        "    self.max_epsilon = max_epsilon\n",
        "    self.min_epsilon = min_epsilon\n",
        "    self.target_update = target_update\n",
        "    self.gamma = gamma # discout factor\n",
        "\n",
        "    self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    self.dqn = Network(obs_dim, act_dim).to(self.device)\n",
        "    self.dqn_target = Network(obs_dim, act_dim).to(self.device)\n",
        "    self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "    self.dqn_target.eval()\n",
        "\n",
        "    self.optimizer = optim.Adam(self.dqn.parameters())\n",
        "    self.transitions = list()\n",
        "    self.is_test = False\n",
        "\n",
        "\n",
        "  def select_action(self, obs):\n",
        "    # select an action given an observation\n",
        "    if self.epsilon > np.random.random():\n",
        "      selected_action = self.env.action_space.sample()\n",
        "    else:\n",
        "      selected_action = self.dqn(torch.FloatTensor(obs).to(self.device)).argmax()\n",
        "      selected_action = selected_action.detach().cpu().numpy()\n",
        "    if not self.is_test:\n",
        "      self.transition = [obs, selected_action]\n",
        "\n",
        "    return selected_action\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"Take an action and return the response of the env.\"\"\"\n",
        "    next_state, reward, terminated, truncated, _ = self.env.step(action)\n",
        "    done = terminated or truncated\n",
        "\n",
        "    if not self.is_test:\n",
        "      self.transition += [reward, next_state, done]\n",
        "      self.memory.store(*self.transition)\n",
        "\n",
        "    return next_state, reward, done\n",
        "\n",
        "\n",
        "  def update_model(self):\n",
        "    samples = self.memory.sample()\n",
        "    loss = self._compute_dqn_loss(samples)\n",
        "    self.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "  def _compute_dqn_loss(self, samples):\n",
        "    # return computed dqn loss\n",
        "    device = self.device  # for shortening the following lines\n",
        "    state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
        "    next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
        "    action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
        "    reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
        "    done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
        "\n",
        "    curr_q_value = self.dqn(state).gather(1, action)\n",
        "    print(curr_q_value.shape)\n",
        "    next_q_value = self.dqn_target(\n",
        "            next_state\n",
        "        ).max(dim=1, keepdim=True)[0].detach()\n",
        "    print(next_q_value.shape)\n",
        "    mask = 1 - done\n",
        "    target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
        "    # calculate dqn loss\n",
        "    loss = F.smooth_l1_loss(curr_q_value, target)\n",
        "    return loss\n",
        "\n",
        "  def train(self, num_frames, plotting_interval:int=200):\n",
        "    \"\"\"\n",
        "    Train the RL agent\n",
        "    \"\"\"\n",
        "    self.is_test = False\n",
        "    state, _ = self.env.reset(seed=self.seed)\n",
        "    update_cnt = 0\n",
        "    epsilons = []\n",
        "    losses = []\n",
        "    scores = []\n",
        "    score = 0\n",
        "\n",
        "    for frame_idx in range(0, num_frames+1):\n",
        "      action = self.select_action(state)\n",
        "      next_state, reward, done = self.step(action)\n",
        "\n",
        "      state = next_state\n",
        "      score += reward\n",
        "\n",
        "      # if episode ends\n",
        "      if done:\n",
        "          state, _ = self.env.reset(seed=self.seed)\n",
        "          scores.append(score)\n",
        "          score = 0\n",
        "\n",
        "      # if training is ready\n",
        "      if len(self.memory) >= self.batch_size:\n",
        "          loss = self.update_model()\n",
        "          losses.append(loss)\n",
        "          update_cnt += 1\n",
        "\n",
        "          # linearly decrease epsilon\n",
        "          self.epsilon = max(\n",
        "              self.min_epsilon, self.epsilon - (\n",
        "                  self.max_epsilon - self.min_epsilon\n",
        "              ) * self.epsilon_decay\n",
        "          )\n",
        "          epsilons.append(self.epsilon)\n",
        "\n",
        "          # if hard update is needed\n",
        "          if update_cnt % self.target_update == 0:\n",
        "              self._target_hard_update()\n",
        "\n",
        "      # plotting\n",
        "      if frame_idx % plotting_interval == 0:\n",
        "          self._plot(frame_idx, scores, losses, epsilons)\n",
        "\n",
        "    self.env.close()\n",
        "\n",
        "\n",
        "  def test(self, video_folder:str):\n",
        "    \"\"\"Test the agent.\"\"\"\n",
        "    self.is_test = True\n",
        "\n",
        "    # for recording a video\n",
        "    naive_env = self.env\n",
        "    # create new environment for recording video\n",
        "    self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
        "\n",
        "    state, _ = self.env.reset(seed=self.seed)\n",
        "    done = False\n",
        "    score = 0\n",
        "\n",
        "    # we run only a single episode of the environment\n",
        "    while not done:\n",
        "      action = self.select_action(state)\n",
        "      next_state, reward, done = self.step(action)\n",
        "\n",
        "      state = next_state\n",
        "      score += reward\n",
        "\n",
        "    print(\"score: \", score)\n",
        "    self.env.close()\n",
        "\n",
        "    # reset\n",
        "    self.env = naive_env\n",
        "\n",
        "  def _target_hard_update(self):\n",
        "        \"\"\"Hard update: target <- local.\"\"\"\n",
        "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
        "\n",
        "  def _plot(\n",
        "      self,\n",
        "      frame_idx: int,\n",
        "      scores: List[float],\n",
        "      losses: List[float],\n",
        "      epsilons: List[float],\n",
        "  ):\n",
        "      \"\"\"Plot the training progresses.\"\"\"\n",
        "      clear_output(True)\n",
        "      plt.figure(figsize=(20, 5))\n",
        "      plt.subplot(131)\n",
        "      plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
        "      plt.plot(scores)\n",
        "      plt.subplot(132)\n",
        "      plt.title('loss')\n",
        "      plt.plot(losses)\n",
        "      plt.subplot(133)\n",
        "      plt.title('epsilons')\n",
        "      plt.plot(epsilons)\n",
        "      plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "pX5K2OO4pXmn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Environment\n",
        "Here we setup the environment for the experiment, we will be using the 2d cartpole environment"
      ],
      "metadata": {
        "id": "jwYmPGJs4IxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# environment\n",
        "env = gym.make(\"CartPole-v1\", max_episode_steps=200, render_mode=\"rgb_array\")"
      ],
      "metadata": {
        "id": "0dOwB3rAsSJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the random seed to control variabilty of the experiment\n",
        "seed = 777\n",
        "\n",
        "def seed_torch(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.backends.cudnn.enabled:\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "np.random.seed(seed)\n",
        "seed_torch(seed)"
      ],
      "metadata": {
        "id": "tUDvIYMz4ZH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "num_frames = 10000\n",
        "memory_size = 1000\n",
        "batch_size = 32\n",
        "target_update = 100\n",
        "epsilon_decay = 1 / 2000\n",
        "video_folder=\"videos/dqn\"\n",
        "\n",
        "agent = DQNAgent(env, memory_size, batch_size, target_update, epsilon_decay, seed)"
      ],
      "metadata": {
        "id": "fd0Zgi5l4l8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and Test DQN model\n",
        "In this section we will train and test the DQN model iteratively on the cartpole environment"
      ],
      "metadata": {
        "id": "hlM-ww0m5GMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.train(num_frames=num_frames)"
      ],
      "metadata": {
        "id": "bIBFQyxX4ufa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.test(video_folder)"
      ],
      "metadata": {
        "id": "V_dxzvQn4qjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.train(num_frames=num_frames)"
      ],
      "metadata": {
        "id": "spPvhdyY4sDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.test(video_folder)"
      ],
      "metadata": {
        "id": "od6oRO0t41QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Render Video\n",
        "In this section we will render the video that was generated during the testing of the agent model"
      ],
      "metadata": {
        "id": "056dkZAB5Dh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import glob\n",
        "import io\n",
        "import os\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "\n",
        "def ipython_show_video(path: str) -> None:\n",
        "    \"\"\"Show a video at `path` within IPython Notebook.\"\"\"\n",
        "    if not os.path.isfile(path):\n",
        "        raise NameError(\"Cannot access: {}\".format(path))\n",
        "\n",
        "    video = io.open(path, \"r+b\").read()\n",
        "    encoded = base64.b64encode(video)\n",
        "\n",
        "    display(HTML(\n",
        "        data=\"\"\"\n",
        "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
        "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
        "        </video>\n",
        "        \"\"\".format(encoded.decode(\"ascii\"))\n",
        "    ))\n",
        "\n",
        "\n",
        "def show_latest_video(video_folder: str) -> str:\n",
        "    \"\"\"Show the most recently recorded video from video folder.\"\"\"\n",
        "    list_of_files = glob.glob(os.path.join(video_folder, \"*.mp4\"))\n",
        "    for file in list_of_files\n",
        "      ipython_show_video(file)\n",
        "    return list_of_files\n",
        "\n",
        "\n",
        "list_of_files = show_latest_video(video_folder=video_folder)\n",
        "print(\"Played:\", list_of_files)"
      ],
      "metadata": {
        "id": "dD-4_e1m5V16"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}